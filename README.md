# За пределами анкеты: как звезды, погода и новостной фон влияют на NPS

Этот репозиторий содержит код и материалы для исследования, представленного в рамках доклада на конференции Researсh Expo 25 

## О проекте

Исследование посвящено анализу волатильности метрики NPS (Net Promoter Score) на телеком-рынке. 
Часто стандартный анализ по профилю абонента не может объяснить резкие колебания показателя.
Наша гипотеза заключается в том, что значительная часть этой волатильности является «шумом», вызванным внешним контекстом, в котором находится респондент в момент опроса.

**Основной исследовательский вопрос:** Что в большей степени определяет оценку клиента — то, **КТО** он есть (его "дневник жизни" с оператором и профиль), или то, **ЧТО** происходит вокруг него (внешний контекст)?

Для ответа на этот вопрос мы объединили более 500 тыс. ответов абонентов (2022-2024 гг.) с большим набором внешних данных и построили объясняющую модель на основе машинного обучения (CatBoost).

### Используемые данные

1.  **Внутренние данные:**
    *   Ежедневный трекинг NPS (оценка по шкале от 0 до 10, три сегмента по модели NPS, дата опроса, вес респондента)
    *   Метрики, отвечающие за диагностику Клиентского опыта
    *   Социально-демографический профиль абонента (регион, пол, возраст и т.д.)
      
2.  **Внешние данные:**
    *   **Календарь:** Сезонность, праздники и каникулы, выходные, даты зарплат, «синие понедельники» и т.д.
    *   **Погода:** Температура, осадки, давление, ветер, солнечность и т.д. (с помощью `meteostat`)
    *   **Астрология:** Знаки Солнца, фаза Луны, ретроградность планет, олнечные и лунные затмения, накопленная астронапряженность (с помощью `ephem`)
    *   **Геомагнитная обстановка:** kp и ap-индексы магнитных бурь (архив NOAA)
    *   **Новостной фон:** Ключевые социально-экономические и политические события, агрегированные по тональности и тематике

## Структура проекта

```
nps-context-analysis/
├── data/                 # Папка для всех входных данных
│   ├── events.tsv        # Хронология новостных событий за 22-24 год, собранных с лент ведущих информагентств (ТАСС, Интерфакс, РБК и другие) и каталогизированных по тематикам 
│   ├── kp_index.json     # Данные по kp-индексу
│   └── ap_index.json     # Данные по ap-индексу
│   └── (your_source_dataset.csv) # Исходный датасет с NPS (помещается сюда вручную)
│
├── cache/                # Кэш для погодных данных (создается автоматически)
├── main.py               # Главный скрипт для обогащения данных и обучения модели
├── requirements.txt      # Список необходимых Python-библиотек
└── README.md             # Этот файл
```

## Как запустить

1.  **Скачайте проект:**
    Нажмите зеленую кнопку **`< > Code`** -> **Download ZIP**. Распакуйте архив.

2.  **Установите зависимости:**
    Откройте терминал (командную строку), перейдите в папку с проектом и выполните:
    ```bash
    pip install -r requirements.txt
    ```

3.  **Подготовьте данные:**
    *   Поместите ваш исходный CSV-файл с данными NPS в папку `data/`.
    *   Откройте файл `main.py` в текстовом редакторе и убедитесь, что переменная `SOURCE_DATA_PATH` (строка ~30) указывает на имя вашего файла.

4.  **Запустите скрипт:**
    В терминале, находясь в папке проекта, выполните:
    ```bash
    python main.py
    ```

Скрипт последовательно выполнит обогащение данных, сохранит промежуточный файл `enriched_nps_data.csv.gz`, проведет кросс-валидацию модели и выведет в консоль результаты (метрики качества и важность факторов).

## Практическая значимость

Исследование предоставляет индустрии инструмент для более точной интерпретации колебаний метрик удовлетворенности. Оно позволяет количественно оценить, вызваны ли изменения характеристиками аудитории или внешними событиями, влияющими на всех.
Это помогает избежать неверных выводов, сфокусировать ресурсы на реальных, а не кажущихся проблемах, и повысить точность анализа клиентского опыта в целом.
