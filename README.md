# За пределами анкеты: как звезды, погода и новостной фон влияют на NPS

Этот репозиторий содержит код и материалы для исследования, представленного в рамках доклада на конференции Researсh Expo 25 

## О проекте

Исследование посвящено анализу волатильности метрики NPS (Net Promoter Score) на телеком-рынке. 
Часто стандартный анализ по профилю абонента не может объяснить резкие колебания показателя.
Наша гипотеза заключается в том, что значительная часть этой волатильности является «шумом», вызванным внешним контекстом, в котором находится респондент в момент опроса.

**Основной исследовательский вопрос:** Что в большей степени определяет оценку клиента — то, **КТО** он есть (его "дневник жизни" с оператором и профиль), или то, **ЧТО** происходит вокруг него (внешний контекст)?

Для ответа на этот вопрос мы объединили более 500 тыс. ответов абонентов (2022-2024 гг.) с большим набором внешних данных и построили объясняющую модель на основе машинного обучения (CatBoost).

### Используемые данные

1.  **Внутренние данные:**
    *   Ежедневный трекинг NPS (оценка по шкале от 0 до 10, три сегмента по модели NPS, дата опроса, вес респондента)
    *   Социально-демографический профиль абонента (регион, пол, возраст и т.д.)
    *   Метрики, отвечающие за диагностику Клиентского опыта
    * 
2.  **Внешние данные:**
    *   **Календарь:** Праздники, выходные, фазы месяца, близость к зарплате.
    *   **Погода:** Температура, осадки, скорость ветра, длина светового дня (с помощью `meteostat`).
    *   **Астрология:** Фазы луны, ретроградность планет, напряженные аспекты, солнечные и лунные затмения (с помощью `ephem`).
    *   **Геомагнитная обстановка:** Kp и ap-индексы магнитных бурь.
    *   **Новостной фон:** Ключевые социально-экономические и политические события, агрегированные по тональности и тематике.

## Структура проекта

```
nps-context-analysis/
├── data/                 # Папка для всех входных данных
│   ├── events.tsv        # Хронология новостных событий
│   ├── kp_index.json     # Данные по Kp-индексу
│   └── ap_index.json     # Данные по ap-индексу
│   └── (your_source_dataset.csv) # Исходный датасет с NPS (помещается сюда вручную)
│
├── cache/                # Кэш для погодных данных (создается автоматически)
├── main.py               # Главный скрипт для обогащения данных и обучения модели
├── requirements.txt      # Список необходимых Python-библиотек
└── README.md             # Этот файл
```

## Как запустить

1.  **Скачайте проект:**
    Нажмите зеленую кнопку **`< > Code`** -> **Download ZIP**. Распакуйте архив.

2.  **Установите зависимости:**
    Откройте терминал (командную строку), перейдите в папку с проектом и выполните:
    ```bash
    pip install -r requirements.txt
    ```

3.  **Подготовьте данные:**
    *   Поместите ваш исходный CSV-файл с данными NPS в папку `data/`.
    *   Откройте файл `main.py` в текстовом редакторе и убедитесь, что переменная `SOURCE_DATA_PATH` (строка ~30) указывает на имя вашего файла.

4.  **Запустите скрипт:**
    В терминале, находясь в папке проекта, выполните:
    ```bash
    python main.py
    ```

Скрипт последовательно выполнит обогащение данных, сохранит промежуточный файл `enriched_nps_data.csv.gz`, проведет кросс-валидацию модели и выведет в консоль результаты (метрики качества и важность факторов).

## Практическая значимость

Исследование предоставляет индустрии инструмент для более точной интерпретации колебаний метрик удовлетворенности. Оно позволяет количественно оценить, вызваны ли изм
